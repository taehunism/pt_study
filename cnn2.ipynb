{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(\n",
    "    datasets.FashionMNIST('dataset/', train=True, download=True,\n",
    "                         transform=transforms.Compose([\n",
    "                             #증폭 추가\n",
    "                             transforms.RandomHorizontalFlip(),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                         ])\n",
    "                         ),\n",
    "    batch_size=32\n",
    ")\n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = data.DataLoader(\n",
    "    datasets.FashionMNIST('dataset/', train=False, download=True,\n",
    "                         transform=transforms.Compose([\n",
    "                             #증폭 추가\n",
    "                             transforms.RandomHorizontalFlip(),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                         ])\n",
    "                         ),\n",
    "    batch_size=32\n",
    ")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 313)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader) #배치사이즈 32여서 각 길이에 * 32 해주면 됨\n",
    "# 대충 6만개 1만개해서 7만개 -> 잘 했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape #4개의 값 , batch_size, channel, height, width -> 넓이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch_image = torch.squeeze(images[0]) #1을 제거 후 28,28 로 시각화를 해보기 위해 squeeze()함수 사용\n",
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -0.99215686, -0.99215686, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.96862745, -0.99215686, -1.        ,\n",
       "        -1.        , -0.42745095, -0.8980392 , -1.        , -1.        ,\n",
       "        -0.99215686, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-0.9764706 , -1.        , -1.        , -0.96862745, -0.9764706 ,\n",
       "        -0.99215686, -1.        , -1.        , -1.        , -0.5764706 ,\n",
       "        -0.5137255 , -0.00392157,  0.06666672, -0.7176471 , -1.        ,\n",
       "        -0.9764706 , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -0.92156863, -0.90588236, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.81960785, -0.03529412,  0.12941182,\n",
       "         0.05098045,  0.3803922 ,  0.6       , -0.19999999, -1.        ,\n",
       "        -0.9529412 , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-0.88235295, -0.4352941 ,  0.0196079 , -0.3960784 , -0.81960785,\n",
       "        -0.4980392 , -0.14509803,  0.26274514,  0.22352946, -0.1607843 ,\n",
       "         0.39607847,  0.62352943,  0.8509804 ,  0.21568632, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-0.4823529 ,  0.34901965, -0.3098039 ,  0.10588241,  0.14509809,\n",
       "        -0.04313725, -0.05098039, -0.00392157,  0.27843142,  0.69411767,\n",
       "         0.69411767,  0.70980394,  0.7490196 ,  0.62352943, -0.4588235 ,\n",
       "        -1.        , -0.99215686, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        ,  0.79607844,  0.5372549 , -0.03529412, -0.00392157,\n",
       "         0.28627455,  0.67058825,  0.6862745 ,  0.7490196 ,  0.7490196 ,\n",
       "         0.79607844,  0.827451  ,  0.81960785,  0.81960785,  0.5686275 ,\n",
       "        -1.        , -0.99215686, -0.99215686, -0.99215686, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        ,  0.35686278,  0.92156863,  0.7490196 ,  0.73333335,\n",
       "         0.75686276,  0.7411765 ,  0.75686276,  0.78039217,  0.84313726,\n",
       "         0.7882353 ,  0.7490196 ,  0.69411767,  0.7647059 ,  0.43529415,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        ,  0.58431375,  0.90588236,  0.7254902 ,  0.7490196 ,\n",
       "         0.67058825,  0.654902  ,  0.64705884,  0.6627451 ,  0.41176474,\n",
       "         0.5529412 ,  0.67058825,  0.70980394,  0.7882353 ,  0.5137255 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-0.5921569 ,  0.6392157 ,  0.54509807,  0.77254903,  0.6627451 ,\n",
       "         0.75686276,  0.70980394,  0.6313726 ,  0.78039217,  0.32549024,\n",
       "         0.5058824 ,  0.70980394,  0.6627451 ,  0.7254902 ,  0.7176471 ,\n",
       "        -0.90588236, -1.        , -0.9764706 , -0.99215686, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-0.56078434,  0.30980396, -0.06666666,  0.92156863,  0.7254902 ,\n",
       "         0.7411765 ,  0.67058825,  0.6862745 ,  0.73333335,  0.5529412 ,\n",
       "         0.5921569 ,  0.70980394,  0.7254902 ,  0.7411765 ,  0.9137255 ,\n",
       "        -0.2235294 , -1.        , -0.9529412 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -0.27843136,  0.6392157 ,  0.7019608 ,  0.7019608 ,\n",
       "         0.8352941 ,  0.7490196 ,  0.70980394,  0.67058825,  0.81960785,\n",
       "         0.88235295,  0.7882353 ,  0.8039216 ,  0.7882353 ,  0.8509804 ,\n",
       "        -0.5686275 , -1.        , -1.        , -0.96862745, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -0.3960784 ,  1.        ,  0.70980394,  0.6862745 ,\n",
       "         0.79607844,  0.7490196 ,  0.69411767,  0.73333335,  0.7411765 ,\n",
       "         0.7176471 ,  0.7411765 ,  0.7490196 ,  0.7019608 ,  0.77254903,\n",
       "         0.85882354, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.9843137 , -0.94509804, -0.9529412 , -0.96862745,\n",
       "        -0.99215686, -1.        , -1.        ],\n",
       "       [-1.        ,  0.24705887,  0.9137255 ,  0.75686276,  0.6862745 ,\n",
       "         0.7176471 ,  0.7490196 ,  0.75686276,  0.70980394,  0.654902  ,\n",
       "         0.6313726 ,  0.70980394,  0.73333335,  0.67058825,  0.62352943,\n",
       "         0.7882353 ,  0.6       ,  0.13725495, -0.5137255 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.9764706 , -1.        ],\n",
       "       [-1.        ,  0.6862745 ,  0.8666667 ,  0.827451  ,  0.94509804,\n",
       "         0.9607843 ,  0.47450984,  0.3803922 ,  0.8352941 ,  0.75686276,\n",
       "         0.8039216 ,  0.654902  ,  0.60784316,  0.5686275 ,  0.77254903,\n",
       "         0.7019608 ,  0.7411765 ,  0.7254902 ,  0.7882353 ,  0.48235297,\n",
       "        -0.1607843 , -0.35686272, -0.654902  , -0.85882354, -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        ,  0.92941177,  0.81960785,  0.7254902 ,  0.654902  ,\n",
       "         0.73333335,  0.8352941 ,  0.73333335,  1.        ,  1.        ,\n",
       "         0.7490196 ,  0.6156863 ,  0.5137255 ,  0.92156863,  0.24705887,\n",
       "         0.5686275 ,  0.6392157 ,  0.6313726 ,  0.6784314 ,  0.6       ,\n",
       "         0.6313726 ,  0.75686276,  0.73333335,  0.75686276,  0.6313726 ,\n",
       "         0.4666667 , -0.5529412 , -1.        ],\n",
       "       [-1.        ,  0.7647059 ,  0.7882353 ,  0.7411765 ,  0.6392157 ,\n",
       "         0.6       ,  0.64705884,  0.49803925,  0.20784318,  0.47450984,\n",
       "         0.73333335,  0.79607844,  1.        ,  0.17647064, -0.372549  ,\n",
       "         0.88235295,  0.7254902 ,  0.60784316,  0.60784316,  0.60784316,\n",
       "         0.6784314 ,  0.654902  ,  0.654902  ,  0.73333335,  0.75686276,\n",
       "         0.7882353 ,  0.58431375, -0.9764706 ],\n",
       "       [-0.77254903,  0.79607844,  0.75686276,  0.7490196 ,  0.7490196 ,\n",
       "         0.7019608 ,  0.6862745 ,  0.73333335,  0.7176471 ,  0.3176471 ,\n",
       "        -0.08235294, -0.16862744, -0.42745095, -0.49019605,  0.8901961 ,\n",
       "         0.7019608 ,  0.6862745 ,  0.52156866,  0.7254902 ,  0.9529412 ,\n",
       "         0.8352941 ,  0.79607844,  0.79607844,  0.7411765 ,  0.64705884,\n",
       "         0.5529412 ,  0.827451  , -0.23137254],\n",
       "       [-0.47450978,  0.8039216 ,  0.73333335,  0.7254902 ,  0.7411765 ,\n",
       "         0.6392157 ,  0.6627451 ,  0.70980394,  0.7490196 ,  0.8745098 ,\n",
       "         0.92156863,  0.78039217,  0.5294118 ,  0.88235295,  0.67058825,\n",
       "         0.5529412 ,  0.6156863 ,  0.54509807,  0.45098042,  0.69411767,\n",
       "         0.7647059 ,  0.654902  ,  0.60784316,  0.5137255 ,  0.6       ,\n",
       "         0.6627451 ,  0.6       , -0.41176468],\n",
       "       [-0.09803921,  0.6156863 ,  0.60784316,  0.41960788,  0.34901965,\n",
       "         0.38823533,  0.41960788,  0.45882356,  0.6156863 ,  0.56078434,\n",
       "         0.69411767,  0.7647059 ,  0.8509804 ,  0.7254902 ,  0.73333335,\n",
       "         0.7176471 ,  0.6784314 ,  0.58431375,  0.5058824 ,  0.52156866,\n",
       "         0.4901961 ,  0.45098042,  0.54509807,  0.67058825,  0.52156866,\n",
       "         0.43529415,  0.5921569 , -0.62352943],\n",
       "       [-0.27843136,  0.64705884,  0.38823533,  0.30980396,  0.22352946,\n",
       "         0.3803922 ,  0.5058824 ,  0.5529412 ,  0.49803925,  0.5294118 ,\n",
       "         0.49803925,  0.52156866,  0.5372549 ,  0.5686275 ,  0.64705884,\n",
       "         0.654902  ,  0.62352943,  0.67058825,  0.64705884,  0.6       ,\n",
       "         0.5372549 ,  0.43529415,  0.3411765 ,  0.4039216 ,  0.5137255 ,\n",
       "         0.7176471 , -0.04313725, -1.        ],\n",
       "       [-1.        ,  0.33333337,  0.69411767,  0.5058824 ,  0.52156866,\n",
       "         0.47450984,  0.47450984,  0.654902  ,  0.64705884,  0.64705884,\n",
       "         0.6392157 ,  0.6       ,  0.5529412 ,  0.5137255 ,  0.47450984,\n",
       "         0.48235297,  0.47450984,  0.45098042,  0.41960788,  0.37254906,\n",
       "         0.34901965,  0.37254906,  0.49803925,  0.6627451 ,  0.48235297,\n",
       "        -0.41960782, -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -0.54509807, -0.2235294 ,  0.3176471 ,\n",
       "         0.30196083,  0.3803922 ,  0.41960788,  0.427451  ,  0.427451  ,\n",
       "         0.4039216 ,  0.49803925,  0.5137255 ,  0.7254902 ,  0.73333335,\n",
       "         0.9137255 ,  0.90588236,  0.92941177,  0.8980392 ,  0.8745098 ,\n",
       "         0.85882354,  0.7411765 ,  0.5686275 , -0.4823529 , -1.        ,\n",
       "        -1.        , -1.        , -0.9843137 ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.7254902 , -0.6784314 , -0.4352941 , -0.654902  , -0.52156866,\n",
       "        -0.6862745 , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_image.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # kernel error 발생 시 추가\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch_image.numpy(), 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 모델 구조\n",
    "#입력데이터 -> (합성곱 -> 풀링 -> 활성화 함수)반복 -> 평탄화 -> 전결합 레이어 -> 전결합 레이어 -> 분류 결과\n",
    "#CNN 모델 구현\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,5) #입력 채널, 출력채널, 커널사이즈, 보폭(기본값 1)\n",
    "        self.conv2 = nn.Conv2d(10,20,5)\n",
    "        self.drop = nn.Dropout2d() # 출력값에 Dropout 적용\n",
    "        self.fc1 = nn.Linear(320,160) # 입력 레이어의 입력값\n",
    "        self.fc2 = nn.Linear(160,80) # 히든레이어\n",
    "        self.fc3 = nn.Linear(80,10) # 출력레이어 10인 이유 10개 중 1개 분류하는거라\n",
    "    def forward(self, x):\n",
    "        x = f.relu(f.max_pool2d(self.conv1(x),2)) #안에서 부터 시작\n",
    "        # Conv -> max_pool -> ReLU\n",
    "        x= f.relu(f.max_pool2d(self.drop(self.conv2(x)),2))\n",
    "        x = x.view(-1,320)\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = f.dropout(x, training=self.training)\n",
    "        x = f.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cnn().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 \t Loss : 0.8340395092964172\n",
      "Test set : Average Loss 0.8101709948539734, Accuracy : 70.75\n",
      "Train Epoch : 2 \t Loss : 0.84764164686203\n",
      "Test set : Average Loss 0.6395323948860169, Accuracy : 75.14\n",
      "Train Epoch : 3 \t Loss : 0.7327413558959961\n",
      "Test set : Average Loss 0.585728041267395, Accuracy : 76.69\n",
      "Train Epoch : 4 \t Loss : 0.6383975744247437\n",
      "Test set : Average Loss 0.5482423441886902, Accuracy : 78.07\n",
      "Train Epoch : 5 \t Loss : 0.5794485807418823\n",
      "Test set : Average Loss 0.5092884730815888, Accuracy : 80.62\n",
      "Train Epoch : 6 \t Loss : 0.713817834854126\n",
      "Test set : Average Loss 0.49600192198753357, Accuracy : 80.89\n",
      "Train Epoch : 7 \t Loss : 0.5247495174407959\n",
      "Test set : Average Loss 0.47335277967453004, Accuracy : 82.23\n",
      "Train Epoch : 8 \t Loss : 0.5518910884857178\n",
      "Test set : Average Loss 0.4539346468925476, Accuracy : 83.34\n",
      "Train Epoch : 9 \t Loss : 0.5787336230278015\n",
      "Test set : Average Loss 0.43800988593101503, Accuracy : 83.97\n",
      "Train Epoch : 10 \t Loss : 0.487368106842041\n",
      "Test set : Average Loss 0.4295934147119522, Accuracy : 84.14\n",
      "Train Epoch : 11 \t Loss : 0.5381450653076172\n",
      "Test set : Average Loss 0.41302459030151367, Accuracy : 84.93\n",
      "Train Epoch : 12 \t Loss : 0.5746758580207825\n",
      "Test set : Average Loss 0.4045702998638153, Accuracy : 85.13\n",
      "Train Epoch : 13 \t Loss : 0.4401835799217224\n",
      "Test set : Average Loss 0.39089712512493135, Accuracy : 85.47\n",
      "Train Epoch : 14 \t Loss : 0.3581728935241699\n",
      "Test set : Average Loss 0.3842972206115723, Accuracy : 86.13\n",
      "Train Epoch : 15 \t Loss : 0.45313340425491333\n",
      "Test set : Average Loss 0.3792901659011841, Accuracy : 86.00999999999999\n",
      "Train Epoch : 16 \t Loss : 0.33553075790405273\n",
      "Test set : Average Loss 0.3711530079603195, Accuracy : 86.53\n",
      "Train Epoch : 17 \t Loss : 0.46822452545166016\n",
      "Test set : Average Loss 0.3587001338005066, Accuracy : 87.12\n",
      "Train Epoch : 18 \t Loss : 0.3960695266723633\n",
      "Test set : Average Loss 0.36034897775650027, Accuracy : 87.07000000000001\n",
      "Train Epoch : 19 \t Loss : 0.378606379032135\n",
      "Test set : Average Loss 0.3537061415195465, Accuracy : 86.9\n",
      "Train Epoch : 20 \t Loss : 0.3080551326274872\n",
      "Test set : Average Loss 0.356387522149086, Accuracy : 86.91\n",
      "Train Epoch : 21 \t Loss : 0.380465030670166\n",
      "Test set : Average Loss 0.34505377254486086, Accuracy : 87.3\n",
      "Train Epoch : 22 \t Loss : 0.41143450140953064\n",
      "Test set : Average Loss 0.34130076711177826, Accuracy : 87.64999999999999\n",
      "Train Epoch : 23 \t Loss : 0.37471234798431396\n",
      "Test set : Average Loss 0.3353375101327896, Accuracy : 87.5\n",
      "Train Epoch : 24 \t Loss : 0.3101058602333069\n",
      "Test set : Average Loss 0.328813050866127, Accuracy : 87.83\n",
      "Train Epoch : 25 \t Loss : 0.34264540672302246\n",
      "Test set : Average Loss 0.33124295258522035, Accuracy : 87.83\n",
      "Train Epoch : 26 \t Loss : 0.4109339118003845\n",
      "Test set : Average Loss 0.3283320754289627, Accuracy : 87.85\n",
      "Train Epoch : 27 \t Loss : 0.27503347396850586\n",
      "Test set : Average Loss 0.32731828396320345, Accuracy : 88.0\n",
      "Train Epoch : 28 \t Loss : 0.33827638626098633\n",
      "Test set : Average Loss 0.3219248035669327, Accuracy : 88.2\n",
      "Train Epoch : 29 \t Loss : 0.25275132060050964\n",
      "Test set : Average Loss 0.31830493762493134, Accuracy : 88.36\n",
      "Train Epoch : 30 \t Loss : 0.2914794087409973\n",
      "Test set : Average Loss 0.31917495834827425, Accuracy : 88.28\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "EPOCHS = 30 #학습 횟수\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, tarage = data.to(device), target.to(device) #학습 데이터를 device 메모리로 전달\n",
    "        optimizer.zero_grad() #기울기 초기화\n",
    "        output = model(data) #output은 모델의 예측값\n",
    "        loss = f.cross_entropy(output, target) #예측값과 실제값의 오차 계산\n",
    "        loss.backward() #기울기 계산\n",
    "        optimizer.step() #최적화 알고리즘으로 가중치 수정\n",
    "    print(f\"Train Epoch : {epoch} \\t Loss : {loss.item()}\") #학습을 하면 할 수록 오차가 줄어드는 것을 볼 수 있음\n",
    "    \n",
    "    model.eval() #검증 모드 validation\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): #검증 할 때는기울기 계산할 필요 없음\n",
    "        for data, target in test_loader: #테스트 데이터만큼 반복\n",
    "            data, target = data.to(device), target.to(device) #데이터 device 메모리로 전달\n",
    "            output = model(data) #모델의 예측값\n",
    "            test_loss += f.cross_entropy(output, target, reduction='sum').item() #모든 오차의 합 계산\n",
    "            pred = output.argmax(dim=1, keepdim=True) #차원, 차원유지 옵션 , #가장 큰 값이 모델의 예측값\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() #예측값과 실제값이 같은 경우 1 더함\n",
    "            #반복이 끝나면 correct는 정답을 맞춘 갯수\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            target = target.detach().cpu().numpy()\n",
    "            for i in range(len(pred)):\n",
    "                predictions.append(pred[i])\n",
    "                targets.append(target[i])\n",
    "                \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(f\"Test set : Average Loss {test_loss}, Accuracy : {correct/len(test_loader.dataset)*100}\") #백분율로 정확도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas, labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), tensor(9))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape, labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 12.1589,  0.0000, 14.4615,\n",
       "         4.1753, 18.7540], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(datas)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25247,    14,   789,  1390,   120,    53,  1980,     1,   406,\n",
       "            0],\n",
       "       [   35, 28580,    35,  1050,   148,    37,    84,     0,    31,\n",
       "            0],\n",
       "       [  410,     5, 23488,   380,  3622,    55,  1911,     2,   127,\n",
       "            0],\n",
       "       [  907,   127,   346, 26547,  1022,     0,   966,     0,    84,\n",
       "            1],\n",
       "       [   30,    13,  2573,  1290, 23889,     4,  2091,     0,   110,\n",
       "            0],\n",
       "       [   17,     1,     0,    66,     0, 26804,     1,  2333,   112,\n",
       "          666],\n",
       "       [ 6475,    13,  4608,  1064,  3097,    33, 14050,     1,   659,\n",
       "            0],\n",
       "       [    0,     0,     0,     0,     0,   392,     0, 28550,    14,\n",
       "         1044],\n",
       "       [   66,    19,   262,   164,   124,   177,   361,   194, 28612,\n",
       "           21],\n",
       "       [    4,     0,     0,    17,     1,   208,     1,  1826,    26,\n",
       "        27917]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#성능평가 지표 2가지 , 분류모델에 적용 가능\n",
    "    #혼동 행렬 - 사이킷 런 라이브러리에 있음\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(targets,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80     30000\n",
      "           1       0.99      0.95      0.97     30000\n",
      "           2       0.73      0.78      0.76     30000\n",
      "           3       0.83      0.88      0.86     30000\n",
      "           4       0.75      0.80      0.77     30000\n",
      "           5       0.97      0.89      0.93     30000\n",
      "           6       0.66      0.47      0.55     30000\n",
      "           7       0.87      0.95      0.91     30000\n",
      "           8       0.95      0.95      0.95     30000\n",
      "           9       0.94      0.93      0.94     30000\n",
      "\n",
      "    accuracy                           0.85    300000\n",
      "   macro avg       0.84      0.85      0.84    300000\n",
      "weighted avg       0.84      0.85      0.84    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    #분류 보고서\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
